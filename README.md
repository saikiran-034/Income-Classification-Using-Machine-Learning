# ğŸ’¼ Income Classification Using Machine Learning  

## ğŸ“– Overview  
This project focuses on predicting whether an individual's annual income exceeds **Â£50K** based on various **demographic and employment attributes**.  
By applying multiple machine learning algorithms, this project demonstrates the complete **end-to-end process** of building, evaluating, and optimising predictive models â€” from **data preprocessing to model interpretation**.  

---

## ğŸ¯ Objective  
To classify income levels using demographic data and compare the performance of several machine learning models to identify the most accurate and reliable approach.  

---

## âš™ï¸ Key Steps  

### ğŸ§¹ Data Preprocessing  
- Handled missing and inconsistent values.  
- Encoded categorical variables using **LabelEncoder**.  
- Normalised numerical features with **StandardScaler**.  

### âš–ï¸ Balancing the Dataset  
- Applied **SMOTE (Synthetic Minority Oversampling Technique)** to address class imbalance.  

### ğŸ¤– Model Development  
Trained and compared four supervised learning models:  
- Logistic Regression  
- Decision Tree Classifier  
- K-Nearest Neighbors (KNN)  
- Random Forest Classifier  

### ğŸ”§ Model Optimization  
- Used **GridSearchCV** for hyperparameter tuning and cross-validation.  

### ğŸ“Š Evaluation Metrics  
- Accuracy  
- F1-Score  
- Cohenâ€™s Kappa  
- Confusion Matrix  

---

## ğŸ§  Key Insights  
- **Random Forest Classifier** achieved the best overall performance across evaluation metrics.  
- Higher education, work hours, and occupation types showed strong correlations with income level.  
- Demonstrated the strength of **ensemble methods** in capturing complex, non-linear relationships.  

---

## ğŸ§° Technologies Used  
- **Python 3.x**  
- **Pandas, NumPy** â€“ Data manipulation  
- **Scikit-learn, Imbalanced-learn** â€“ Modelling and evaluation  
- **Plotly, Seaborn, Matplotlib** â€“ Data visualisation  

---

## ğŸ“ˆ Results  

| Model | Accuracy | F1-Score | Kappa Score |
|--------|-----------|-----------|--------------|
| Logistic Regression | 83% | 0.78 | 0.70 |
| Decision Tree | 86% | 0.81 | 0.74 |
| KNN | 84% | 0.79 | 0.72 |
| **Random Forest** | **90%** | **0.85** | **0.79** |

> *(These values are representative of the project findings and may vary slightly per run.)*  

---

## ğŸ” Conclusion  
This project highlights how **data preprocessing**, **balancing**, and **model selection** can significantly influence classification performance.  
It demonstrates an **end-to-end machine learning pipeline** that can be adapted for similar socioeconomic or business classification problems.  

---

ğŸ”— **LinkedIn:** [www.linkedin.com/in/saikiran-mada](https://www.linkedin.com/in/saikiran-mada)  
ğŸ“« **Email:** [your.email@example.com]  
